{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Fine-tuning LLMs\n",
        "\n",
        "## Aprendizagem com contexto\n",
        "\n",
        "O Aprendizado com contexto é uma técnica utilizada para melhorar o desempenho de modelos de linguagem, como o LLM (Large Language Model), por meio da inclusão de exemplos específicos de tarefas diretamente no prompt. Essencialmente, essa abordagem oferece ao modelo um \"plano de ação\" sobre o que se espera dele. Ao ser alimentado com exemplos relevantes dentro do contexto da solicitação, o modelo pode identificar padrões e adaptar suas respostas de maneira mais precisa e eficiente.\n",
        "\n",
        "A grande vantagem do Aprendizado com contexto é que o modelo não precisa de treinamento adicional para compreender a tarefa em questão. Em vez disso, ele utiliza o contexto fornecido para inferir as melhores respostas com base nos exemplos apresentados.\n",
        "\n",
        "### Como utilizar no ChatGPT\n",
        "\n",
        "No ícone de perfil, selecione a opção *Personalizar ChatGPT*. Na primeira opção *O que você gostaria que o ChatGPT soubesse a seu respeito para dar melhores respostas* você pode adicionar um contexto para como o GPT pode conversar contigo.\n",
        "\n",
        "Na outra opção, *Como o ChatGPT deveria responder*, você pode adicionar contexto para os tipos de saída, como o seguinte:\n",
        "\n",
        "_\"Se uma pergunta é de programação, responda com o código documentado e com estilo seguindo as melhores práticas de programação, como padrões de projeto, PEP8 e documentação no estilo Google.\"_\n",
        "\n",
        "## Zero-shot / few-shots\n",
        "\n",
        "A inferência \"zero-shot\" incorpora os dados de entrada diretamente no prompt, sem a necessidade de exemplos adicionais. Nesse caso, o modelo é solicitado a realizar a tarefa com base apenas no contexto fornecido, sem exemplos pré-executados. Isso pode ser eficaz em muitas situações, mas, caso os resultados desejados não sejam alcançados, podem ser usadas outras técnicas, como o _few-shots_.\n",
        "\n",
        "A inferência \"few-shot\" adiciona múltiplos exemplos de auxílio. Essas abordagens ajudam modelos de LLMs a performar de maneira mais eficiente, pois fornecem um contexto mais claro sobre o que se espera como saída, orientando o modelo a gerar respostas mais precisas.\n",
        "\n",
        "### Como utilizar no ChatGPT\n",
        "\n",
        "Prompt inicial para dar o contexto:\n",
        "```text\n",
        "Você receberá uma linha de um arquivo CSV com informações do cartão de crédito. Divida essas informações em LAZER, NECESSIDADE e TRABALHO.\n",
        "\n",
        "Retorne para mim um arquivo CSV com as colunas \"código,informação\".\n",
        "\n",
        "Exemplo:\n",
        "\n",
        "data,código,valor,tipo\n",
        "03/09/2024,d5g489fc,-30.50,Compra no débito - Mercado Econômico\n",
        "02/09/2024,c4f378db,20.00,Transferência recebida pelo Pix - LOJA DE DOCES\n",
        "24/10/2024,j1m045li,-500.56,Transferência enviada pelo Pix - MERCADINHO\n",
        "30/10/2024,f7i601he,-87.54,Compra no crédito - Posto XYZ\n",
        "\n",
        "Saída esperada:\n",
        "\n",
        "código,informação\n",
        "d5g489fc,NECESSIDADE\n",
        "c4f378db,LAZER\n",
        "j1m045li,NECESSIDADE\n",
        "f7i601he,TRABALHO\n",
        "\n",
        "Faça essa modificação para a seguinte linha:\n",
        "\n",
        "03/09/2024,e6h590gd,-6.89,Compra no débito - Estacionamento Central\n",
        "```\n",
        "\n",
        "A partir disso, qualquer entrada no formato definido será processada de acordo com a saída esperada, dependendo do tamanho do modelo.\n",
        "\n",
        "Exemplos de entradas:\n",
        "```text\n",
        "data,valor,codigo,descricao\n",
        "03/09/2024,-22.13,b900976c,Transferência enviada pelo Pix - MERCADINHO ESTRELA - 11.111.222/0001-33 - BANCO ABC (1234) Agência: 567 Conta: 101112-3\n",
        "07/09/2024,-37.06,fae5940d,Compra no débito - Estacionamento Central\n",
        "04/09/2024,21.36,9947be3d,Transferência recebida pelo Pix - LOJA DE DOCES - 44.777.888/0001-99 - BANCO TUV (4567) Agência: 876 Conta: 43210-9\n",
        "04/09/2024,-64.95,31fc9376,Compra no débito - Restaurante Bella Vista\n",
        "06/09/2024,-18.77,aeafab53,Compra no débito - Restaurante Gourmet\n",
        "05/09/2024,-56.16,6f6ec6ae,Compra no crédito - Mercado Econômico\n",
        "07/09/2024,-96.05,bd8d8e3c,Compra no crédito - Café Expresso\n",
        "05/09/2024,12.12,325d56ea,Transferência enviada pelo Pix - LANCHONETE DO JOÃO - 33.555.666/0001-77 - BANCO PQR (9876) Agência: 321 Conta: 54321-0\n",
        "02/09/2024,86.59,51950070,Transferência recebida pelo Pix - LOJA DE DOCES - 44.777.888/0001-99 - BANCO TUV (4567) Agência: 876 Conta: 43210-9\n",
        "05/09/2024,42.93,3d9186dc,Transferência enviada pelo Pix - MERCADINHO ESTRELA - 11.111.222/0001-33 - BANCO ABC (1234) Agência: 567 Conta: 101112-3\n",
        "```\n",
        "\n",
        "## Fine-tuning supervisionado\n",
        "\n",
        "As técnicas usadas anteriormente no prompt do usuário têm como objetivo otimizar a saída do modelo, ajustando-a melhor às preferências do usuário. O problema é que elas nem sempre funcionam, especialmente para LLMs menores. Assim, um fine-tuning dos pesos do modelo se faz necessário.\n",
        "\n",
        "Ferramentas disponíveis: LangChain, LlamaIndex, Hugging Face Transformers...\n"
      ],
      "metadata": {
        "id": "xEbyur2lnG06"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xAWz7ohuux6Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}